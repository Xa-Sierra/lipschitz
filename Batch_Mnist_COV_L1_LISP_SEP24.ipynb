{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EqPYZwYX2plJ",
        "outputId": "8f59ef86-d354-4355-8585-cbe8186a9fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: celluloid in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from celluloid) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->celluloid) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->celluloid) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install celluloid\n",
        "%pip install torch torchvision\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/local_lipschitz-master')\n",
        "import network_bound\n",
        "import my_config\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from celluloid import Camera\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.manifold import TSNE\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kov1Xmn3YFk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def graph(network,text):\n",
        "  data_p=example_data[0:2000]\n",
        "  test_p=example_targets[0:2000]\n",
        "\n",
        "  fig = plt.figure()\n",
        "  x_pred, x_prev = network(data_p.to(device))\n",
        "  vals= x_pred.detach().cpu().numpy()\n",
        "\n",
        "  tsne = TSNE(n_components=3, perplexity=50, n_iter=300)\n",
        "  X_tsne = tsne.fit_transform(vals)\n",
        "\n",
        "  #ax = fig.add_subplot(1,2,2,projection='3d')\n",
        "  ax = fig.add_subplot(projection='3d')\n",
        "  scatter=  ax.scatter(\n",
        "      xs=X_tsne[:, 0],\n",
        "      ys=X_tsne[:, 1],\n",
        "      zs=X_tsne[:, 2],\n",
        "      c=test_p,\n",
        "      cmap='tab20b',\n",
        "      label=test_p\n",
        "  )\n",
        "  ax.set_xlabel('X')\n",
        "  ax.set_ylabel('Y')\n",
        "  ax.set_zlabel('Z')\n",
        "  legend1 = ax.legend(*scatter.legend_elements(),\n",
        "                    loc=\"lower left\", title=\"Classes\")\n",
        "  ax.add_artist(legend1)\n",
        "  plt.title(text)\n",
        "\n",
        "  #plt.show()\n",
        "\n",
        "def graph_cam(network, si, beta):\n",
        "  data_p=example_data[0:2000]\n",
        "  test_p=example_targets[0:2000]\n",
        "\n",
        "  x_pred, x_prev = network(data_p.to(device))\n",
        "  vals= x_pred.detach().cpu().numpy()\n",
        "\n",
        "  tsne = TSNE(n_components=3, perplexity=50, n_iter=300)\n",
        "  X_tsne = tsne.fit_transform(vals)\n",
        "\n",
        "  #ax = fig.add_subplot(1,2,2,projection='3d')\n",
        "  ax.scatter(\n",
        "      xs=X_tsne[:, 0],\n",
        "      ys=X_tsne[:, 1],\n",
        "      zs=X_tsne[:, 2],\n",
        "      c=test_p,\n",
        "      cmap='tab20b'\n",
        "  )\n",
        "  ax.set_xlabel('X')\n",
        "  ax.set_ylabel('Y')\n",
        "  ax.set_zlabel('Z')\n",
        "  text =str(si)+'  beta= '+ str(beta)\n",
        "  plt.title(text)\n",
        "\n",
        "  #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAHQGxvD3lQc"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data=data.to(device)\n",
        "      target=target.to(device)\n",
        "      output, x_prev = network(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n",
        "  return correct / len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OMju1p0E3oPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "98b107c8-092b-4c79-f3b5-0b977bfddeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2048, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epsi=0.01\n",
        "batch_size_train = 2048\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.3\n",
        "log_interval = 10\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST(root='./files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST(root='./files/''/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)\n",
        "\n",
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.to(device)\n",
        "example_targets.to(device)\n",
        "\n",
        "print(example_data.shape)\n",
        "#pause = input()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfINGzkP3zA5"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128,10 )\n",
        "        self.fc3 = nn.Linear(3, 10)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        #x = F.relu(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        #x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        #x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        #x = F.relu(x)\n",
        "        #x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        # x = F.relu(x)\n",
        "\n",
        "        y=x\n",
        "       # x = self.fc3(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cc4_86t32Cs"
      },
      "outputs": [],
      "source": [
        "class ClassDistancePenaltyLoss(nn.Module):\n",
        "    def __init__(self, num_classes, norma):\n",
        "        super(ClassDistancePenaltyLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.norma=norma\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        vc=torch.zeros(1).to(device)\n",
        "        for j in range (self.num_classes): #para cada clase\n",
        "\n",
        "          cla=x[t==j].to(device)\n",
        "          ccov=torch.cov(torch.t(cla))\n",
        "          if self.norma:\n",
        "              ncla=torch.linalg.vector_norm(torch.diag(ccov,0),ord=1)\n",
        "              #ncla=torch.linalg.vector_norm(torch.diag(ccov,0),ord=2)\n",
        "              #ncla=torch.linalg.vector_norm(torch.diag(ccov,0),ord=np.inf)\n",
        "          else:\n",
        "              ccov=torch.cov(torch.t(cla))\n",
        "              ncla=torch.trace(ccov)\n",
        "          vc=vc+ncla\n",
        "        penalty2=0\n",
        "        penalty1=vc/self.num_classes\n",
        "        return penalty1, penalty2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt3O5XCG35LZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363628f9-5b8d-474c-acb6-7c6266d1e5d7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inicia\n",
            "cpu\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3045, Accuracy: 873/10000 (9%)\n",
            "\n",
            "Train Epoch: 0 [2048/60000 (0%)]\tLoss: 2.304493\n",
            "Train Epoch: 0 [2048/60000 (33%)]\tLoss: 2.217216\n",
            "Train Epoch: 0 [2048/60000 (67%)]\tLoss: 2.107217\n",
            "Train Epoch: 1 [2048/60000 (0%)]\tLoss: 1.903257\n",
            "Train Epoch: 1 [2048/60000 (33%)]\tLoss: 1.574309\n",
            "Train Epoch: 1 [2048/60000 (67%)]\tLoss: 1.132455\n",
            "Train Epoch: 2 [2048/60000 (0%)]\tLoss: 0.768529\n",
            "Train Epoch: 2 [2048/60000 (33%)]\tLoss: 0.615145\n",
            "Train Epoch: 2 [2048/60000 (67%)]\tLoss: 0.523955\n",
            "Train Epoch: 3 [2048/60000 (0%)]\tLoss: 0.473424\n",
            "Train Epoch: 3 [2048/60000 (33%)]\tLoss: 0.446614\n",
            "Train Epoch: 3 [2048/60000 (67%)]\tLoss: 0.446852\n",
            "Train Epoch: 4 [2048/60000 (0%)]\tLoss: 0.365456\n",
            "Train Epoch: 4 [2048/60000 (33%)]\tLoss: 0.380699\n"
          ]
        }
      ],
      "source": [
        "print('Inicia')\n",
        "print(device)\n",
        "exes=2000 #numero de ejemplos que se van a utilizar para el entrenamiento\n",
        "norma=False # --- -Evaluamos con la NORMA o no ---------------\n",
        "\n",
        "\n",
        "'''fig = plt.figure(figsize=(6,6),dpi=(1920/16))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "camera= Camera(fig)\n",
        "'''\n",
        "random_seed = 5900\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)\n",
        "network = Net().to(device)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
        "                      momentum=momentum)\n",
        "myloss=ClassDistancePenaltyLoss(10,norma)\n",
        "n_epochs = 5\n",
        "beta=0.9 #covarianza\n",
        "alpha=0.0 #distancia entre medias\n",
        "si= False  #<------------------------------------ACA ESTA EL PARAMETRO-----------\n",
        "#optimizer = optim.Adagrad(network.parameters())\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "test()\n",
        "e=0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data=data.to(device)\n",
        "      target=target.to(device)\n",
        "      e=e+1\n",
        "      optimizer.zero_grad()\n",
        "      output, x_prev = network(data)\n",
        "      loss = F.nll_loss(output, target)\n",
        "      if si:\n",
        "        p1,p2=myloss(x_prev,target)\n",
        "        #loss=loss+beta*p1-alpha*torch.pow(15-p2,2)\n",
        "        loss=loss+beta*p1-alpha*p2\n",
        "        #loss=beta*p1#-alpha*p2 #sin medir la entropia\n",
        "      salir = loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      '''\n",
        "      if salir<0.000000000005:\n",
        "        break\n",
        "      '''\n",
        "      if batch_idx % log_interval == 0:\n",
        "        #print('cov ', valor.detach().cpu().numpy(), 'beta= ', beta)\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch,1 * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_losses.append(loss.item())\n",
        "        train_counter.append(\n",
        "          (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "\n",
        "execution_time = (time.time() - start_time)\n",
        "print('Execution time in seconds: ' + str(execution_time))\n",
        "acc=test()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construimos una clase para cálculo de Simulated Annealing\n",
        "\n",
        "class annealing:\n",
        "    def __init__(self,modelo, T,ro,dist,prob,itera):\n",
        "        super(annealing, self).__init__()\n",
        "        self.modelo=modelo\n",
        "        self.ro=ro\n",
        "        self.T=T\n",
        "        self.dist=dist\n",
        "        self.prob=prob\n",
        "        self.itera=itera\n",
        "\n",
        "    def lipx (self,x1,x2,): #dados dos valores de entrada, esta funcion calcula la L por definicion\n",
        "        #L= np.linalg.norm(f1-f2,2)/np.linalg.norm(x1-x2,2)\n",
        "        f1=self.modelo(x1)[1]#.cpu().detach().numpy()\n",
        "        f2=self.modelo(x2)[1]#.cpu().detach().numpy()\n",
        "\n",
        "        L= torch.linalg.matrix_norm(f1-f2,2)/torch.linalg.matrix_norm(x1-x2,2)\n",
        "        #print(L)\n",
        "        return L\n",
        "\n",
        "    def P(self,x1,x2,xm1,xm2):\n",
        "      Fi= self.lipx(x1,x2).cpu().detach().numpy()\n",
        "      Fj= self.lipx(xm1,xm2).cpu().detach().numpy()\n",
        "\n",
        "      #si la L es mayor entonces se queda con alta probabilidad de quedarse\n",
        "      #si no calculamos una probabilidad que depende de la temperatura\n",
        "      #se podria dejar solo la probabilidad basada en la temepratura\n",
        "      if Fi>Fj:\n",
        "          return 1\n",
        "      else:\n",
        "          return 0.1#np.exp(-(Fj-Fi)/T)\n",
        "\n",
        "    def annea(self,x):\n",
        "      f_lips=[]\n",
        "      val=[]\n",
        "\n",
        "      #estos puntos el fh como referencia para la bola de evaluacion\n",
        "      xa1=x.cpu().detach().numpy() #xi is a point in hiperplaine to test  net and the liopschitz\n",
        "      xa2=x.cpu().detach().numpy()+0.001\n",
        "\n",
        "      #estos tensores representan los dos punta a y b para evaluar L inicialmente\n",
        "      xm1=torch.tensor(xa1,dtype=torch.float32).to(device)\n",
        "      xm2=torch.tensor(xa2,dtype=torch.float32).to(device)\n",
        "\n",
        "      i=0\n",
        "\n",
        "      while(i<self.itera):\n",
        "        if i%100==0:\n",
        "            pppp=0#print(i,self.T,self.prob)#,xm1.cpu().detach().numpy(),xm2.cpu().detach().numpy(),T)\n",
        "        i=i+1\n",
        "        w1 = np.random.uniform(low=-self.dist+xa1, high=self.dist+xa1, size=(x.shape))\n",
        "        w1=torch.tensor(w1,dtype=torch.float32).to(device)\n",
        "        w2 = np.random.uniform(low=-self.dist+xa2, high=self.dist+xa2, size=(x.shape))\n",
        "        w2=torch.tensor(w2,dtype=torch.float32).to(device)\n",
        "\n",
        "        #estos tensores son otros dos puntos aleatorios dentro de la bola\n",
        "        #serviran para evaluar si la L aumenta, queremos hallar el maximo\n",
        "        #de la L local en esa bola ...\n",
        "\n",
        "        x1=w1#.cpu().detach().numpy()\n",
        "        x2=w2#.cpu().detach().numpy()\n",
        "\n",
        "        #se calcula la proba\n",
        "        #print(x1,x2,xm1,xm2)\n",
        "        prob=self.P(x1,x2,xm1,xm2)\n",
        "\n",
        "        #al regresar con la probabilidad solo\n",
        "        #debemos de evaluar de forma aleatoria si ese\n",
        "        #valor se queda o se cambia\n",
        "\n",
        "        ale=np.random.default_rng()\n",
        "\n",
        "        if prob < ale.random():\n",
        "              xm1=xm1\n",
        "              xm2=xm2\n",
        "        else:\n",
        "              xm1=x1\n",
        "              xm2=x2\n",
        "\n",
        "\n",
        "        lx=self.lipx(xm1,xm2) #se llama a la funcion para sacar la L\n",
        "       # print(lx)\n",
        "        val.append(lx.cpu().detach().numpy())\n",
        "        #self.T=self.T/self.ro #enfriando la temperatura en cada iteracion\n",
        "\n",
        "        xa1=xm1.cpu().detach().numpy() #solo para extraer el valor numpy\n",
        "        xa2=xm2.cpu().detach().numpy() #como nuevo punto de inicio\n",
        "\n",
        "      lx=np.max(np.array(val)) #sacar el valor numpy nada mas para devolver\n",
        "      #print('lx ', lx)\n",
        "      return lx,val\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N_XY8rpckj3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE8_WprX44lm",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#---- Cálculo de Lipschitz  de cada una de las clases\n",
        "import random\n",
        "random.seed(10)\n",
        "\n",
        "c=10 #numero de clases a hallar\n",
        "m=10 #numero de muestras a tomar por cada clase\n",
        "\n",
        "#estas lineas definen las capas para el analytical\n",
        "relu =nn.ReLU(inplace=False)\n",
        "flatten = nn.Flatten()\n",
        "network.layers = [network.conv1, relu,\n",
        "              network.conv2, relu,\n",
        "              network.pool,\n",
        "              flatten,\n",
        "              network.fc1,relu,\n",
        "              network.fc2]\n",
        "eps = 0.1\n",
        "batch_size = 32\n",
        "lips=[] #guardamos las L de cada clase aca\n",
        "\n",
        "#valores para annealing\n",
        "T=1.1\n",
        "ro=0.1\n",
        "dist=0.01\n",
        "prob=0.9\n",
        "itera=100\n",
        "\n",
        "metodo='annealing'\n",
        "\n",
        "La=annealing(network, T,ro,dist,prob,itera)\n",
        "\n",
        "for i in range(c): #para cada una de las clases\n",
        "  xc=example_data[example_targets==i]\n",
        "  #print(xc.shape)\n",
        "  lc=torch.zeros(1).to(device)\n",
        "  Lm=[]\n",
        "  for j in range(m): #tomando solo una muestra de todos los ejemplos de la clase\n",
        "\n",
        "\n",
        "    r=random.random()*xc.shape[0]\n",
        "    r=int(r)\n",
        "\n",
        "    x0=xc[r].to(device) #tomamos un ejemplo como punto de inicio\n",
        "    x0=torch.reshape(x0,((1,1,28,28)))\n",
        "\n",
        "    if metodo=='analytical':\n",
        "      # calculate local Lipschitz bound Analitycal\n",
        "      bound = network_bound.local_bound(network, x0, eps, batch_size=batch_size)\n",
        "      np.append(Lm,bound[0].detach().cpu().numpy())\n",
        "\n",
        "    if metodo=='annealing':\n",
        "    #calculando local L con Annealing\n",
        "      bound = La.annea(x0)\n",
        "      #print('bound ', bound[0])\n",
        "      Lm.append(bound[0])\n",
        "\n",
        "  val=np.max(np.array(Lm))    #el maximo de las L\n",
        "  lips.append(val.item())\n",
        "  print('clase ',i)\n",
        "  #print ('Lm ', Lm)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(c):\n",
        "  print(lips[i],'\\t')\n",
        "\n",
        "\n",
        "x0=example_data[0].to(device)\n",
        "x0=torch.reshape(x0,((1,1,28,28)))\n",
        "# calculate local Lipschitz bound\n",
        "\n",
        "\n",
        "bound = network_bound.local_bound(network, x0, eps, batch_size=batch_size)\n",
        "print('\\nLOCAL LIPSCHITZ UPPER BOUND -- Analytical')\n",
        "print('epsilon:', eps)\n",
        "print('bound:', bound,'\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IYTrbrQ4-Gm"
      },
      "outputs": [],
      "source": [
        "text = (str(si)+'  beta= '+ str(beta)+'\\n time= '+str(execution_time)+\n",
        "        '  acc= '+str(acc.detach().cpu().numpy())+'  \\n epoc= '+ str(n_epochs) +\n",
        "        '\\n local lipschitz bound =' + str(bound)+' N= '+str(norma))\n",
        "\n",
        "graph(network,text)\n",
        "plt.show()\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(\"/content/drive/MyDrive/sound.ogg\", autoplay=True))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1zhT19uOE--B_QL1CMfQ4aX67USKMOrBm",
      "authorship_tag": "ABX9TyMwuC61KDf3bmE5RM10s9Xz"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}